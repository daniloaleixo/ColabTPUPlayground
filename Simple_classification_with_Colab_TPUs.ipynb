{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple classification with Colab TPUs.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniloaleixo/ColabTPUPlayground/blob/master/Simple_classification_with_Colab_TPUs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSMMA-ojt_Um",
        "colab_type": "text"
      },
      "source": [
        "# A simple classification model using Keras with Cloud TPUs\n",
        "\n",
        "\n",
        "From tutorial https://colab.research.google.com/github/tensorflow/tpu/blob/master/tools/colab/classification_iris_data_with_keras.ipynb#scrollTo=0DrKs2PGrIhY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y6vk-pbuCzY",
        "colab_type": "text"
      },
      "source": [
        "## Instructions\n",
        "\n",
        "<h3>  &nbsp;&nbsp;Train on TPU&nbsp;&nbsp; <a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a></h3>\n",
        "\n",
        "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
        "   1. Click Runtime again and select **Runtime > Run All**. You can also run the cells manually with Shift-ENTER. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0VOMiBtuGld",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJFtFMSrt0N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "from tensorflow import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC7t287et1H4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72d51ea5-ae15-4ed3-8284-71647322040c"
      },
      "source": [
        "print(tf.__version__)\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/classification_iris_data_with_keras.ipynb')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoC9fwP9uIzU",
        "colab_type": "text"
      },
      "source": [
        "### Resolve TPU Address"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZxNUuGxt51H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "8bf29554-0628-4bd6-fa0a-36a93ee2311c"
      },
      "source": [
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "with tf.Session(TF_MASTER) as session:\n",
        "  print ('List of devices:')\n",
        "  pprint.pprint(session.list_devices())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 6869622526413805163),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7285670502718228777),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8186706504189825486),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14884849411853327437),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14068334488985848823),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 171688651737025768),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12859611169856918027),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8500629764600526047),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10395582212208011528),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7974970897668746612),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2877639946786487272)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJmyZf0YuLA7",
        "colab_type": "text"
      },
      "source": [
        "### FLAGS used as model params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oEfTG-Et8PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model specific parameters\n",
        "\n",
        "# TPU address\n",
        "tpu_address = TF_MASTER\n",
        "\n",
        "# Number of epochs\n",
        "epochs = 50\n",
        "\n",
        "# Number of steps_per_epoch\n",
        "steps_per_epoch = 5\n",
        "\n",
        "# NOTE: Total number of training steps = Number of epochs * Number of steps_per_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vvt2jQ4uPaY",
        "colab_type": "text"
      },
      "source": [
        "### Download training input data and define prediction input & output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thS7MUDpuNgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "PREDICTION_INPUT_DATA = {\n",
        "    'SepalLength': [6.9, 5.1, 5.9, 6.0, 5.5, 6.2, 5.5, 6.3],\n",
        "    'SepalWidth': [3.1, 3.3, 3.0, 3.4, 2.5, 2.9, 4.2, 2.8],\n",
        "    'PetalLength': [5.4, 1.7, 4.2, 4.5, 4.0, 4.3, 1.4, 5.1],\n",
        "    'PetalWidth': [2.1, 0.5, 1.5, 1.6, 1.3, 1.3, 0.2, 1.5],\n",
        "}\n",
        "\n",
        "PREDICTION_OUTPUT_DATA = ['Virginica', 'Setosa', 'Versicolor', 'Versicolor', 'Versicolor', 'Versicolor', 'Setosa', 'Virginica']\n",
        "\n",
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n",
        "\n",
        "def load_data(y_name='Species'):\n",
        "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
        "    train_path, test_path = maybe_download()\n",
        "\n",
        "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0, dtype={'SepalLength': pd.np.float32,\n",
        "        'SepalWidth': pd.np.float32, 'PetalLength': pd.np.float32, 'PetalWidth': pd.np.float32, 'Species': pd.np.int32})\n",
        "    train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0, dtype={'SepalLength': pd.np.float32,\n",
        "        'SepalWidth': pd.np.float32, 'PetalLength': pd.np.float32, 'PetalWidth': pd.np.float32, 'Species': pd.np.int32})\n",
        "    test_x, test_y = test, test.pop(y_name)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgIQ-y1FuUn5",
        "colab_type": "text"
      },
      "source": [
        "### Define a Keras model (2 hidden layers with 10 neurons in each)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CgfRUWnuXlW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "  return keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(4,), activation=tf.nn.relu, name = \"Dense_1\"),\n",
        "    keras.layers.Dense(10, activation=tf.nn.relu, name = \"Dense_2\"),\n",
        "    keras.layers.Dense(3, activation=None, name = \"logits\"),\n",
        "    keras.layers.Dense(3, activation=tf.nn.softmax, name = \"softmax\")\n",
        "  ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k92TLbbhuZO-",
        "colab_type": "text"
      },
      "source": [
        "### Compiling the model with a distribution strategy\n",
        "To make the model usable by a TPU, we first must create and compile it using a distribution strategy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcVkTPXDuX6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a2b611ff-1e40-4dec-a504-2ec8e30a5a18"
      },
      "source": [
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: 10.37.190.2:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.37.190.2:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6869622526413805163)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 8186706504189825486)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 14884849411853327437)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 14068334488985848823)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 171688651737025768)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12859611169856918027)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8500629764600526047)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 10395582212208011528)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7974970897668746612)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 2877639946786487272)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 7285670502718228777)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dqKEi-0ua9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "062cf251-e75e-44eb-f47c-542621530a3f"
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_model()\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1), \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['sparse_categorical_crossentropy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Dense_1 (Dense)              (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "Dense_2 (Dense)              (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "logits (Dense)               (None, 3)                 33        \n",
            "_________________________________________________________________\n",
            "softmax (Dense)              (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 205\n",
            "Trainable params: 205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tnFfskWuiyK",
        "colab_type": "text"
      },
      "source": [
        "### Train the model on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb9EER-Nugfq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66a01756-3540-4aca-faaf-d6d5e7a2b0c8"
      },
      "source": [
        "# Fetch the data\n",
        "(train_x, train_y), (test_x, test_y) = load_data()\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "  train_x.values, train_y.values,\n",
        "  steps_per_epoch = steps_per_epoch,\n",
        "  epochs=epochs,\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
            "8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/adagrad.py:107: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Epoch 1/50\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 1.2084 - sparse_categorical_crossentropy: 1.2084\n",
            "Epoch 2/50\n",
            "5/5 [==============================] - 0s 53ms/step - loss: 0.7590 - sparse_categorical_crossentropy: 0.7590\n",
            "Epoch 3/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.6380 - sparse_categorical_crossentropy: 0.6380\n",
            "Epoch 4/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.5790 - sparse_categorical_crossentropy: 0.5790\n",
            "Epoch 5/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5437 - sparse_categorical_crossentropy: 0.5437\n",
            "Epoch 6/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.5229 - sparse_categorical_crossentropy: 0.5229\n",
            "Epoch 7/50\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.5082 - sparse_categorical_crossentropy: 0.5082\n",
            "Epoch 8/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4975 - sparse_categorical_crossentropy: 0.4975\n",
            "Epoch 9/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4897 - sparse_categorical_crossentropy: 0.4897\n",
            "Epoch 10/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4839 - sparse_categorical_crossentropy: 0.4839\n",
            "Epoch 11/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4818 - sparse_categorical_crossentropy: 0.4818\n",
            "Epoch 12/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4794 - sparse_categorical_crossentropy: 0.4794\n",
            "Epoch 13/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4751 - sparse_categorical_crossentropy: 0.4751\n",
            "Epoch 14/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4714 - sparse_categorical_crossentropy: 0.4714\n",
            "Epoch 15/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4711 - sparse_categorical_crossentropy: 0.4711\n",
            "Epoch 16/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4680 - sparse_categorical_crossentropy: 0.4680\n",
            "Epoch 17/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4690 - sparse_categorical_crossentropy: 0.4690\n",
            "Epoch 18/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4662 - sparse_categorical_crossentropy: 0.4662\n",
            "Epoch 19/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4673 - sparse_categorical_crossentropy: 0.4673\n",
            "Epoch 20/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4634 - sparse_categorical_crossentropy: 0.4634\n",
            "Epoch 21/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4622 - sparse_categorical_crossentropy: 0.4622\n",
            "Epoch 22/50\n",
            "5/5 [==============================] - 0s 34ms/step - loss: 0.4611 - sparse_categorical_crossentropy: 0.4611\n",
            "Epoch 23/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4601 - sparse_categorical_crossentropy: 0.4601\n",
            "Epoch 24/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4597 - sparse_categorical_crossentropy: 0.4597\n",
            "Epoch 25/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4620 - sparse_categorical_crossentropy: 0.4620\n",
            "Epoch 26/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4586 - sparse_categorical_crossentropy: 0.4586\n",
            "Epoch 27/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4580 - sparse_categorical_crossentropy: 0.4580\n",
            "Epoch 28/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4590 - sparse_categorical_crossentropy: 0.4590\n",
            "Epoch 29/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4578 - sparse_categorical_crossentropy: 0.4578\n",
            "Epoch 30/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4620 - sparse_categorical_crossentropy: 0.4620\n",
            "Epoch 31/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4562 - sparse_categorical_crossentropy: 0.4562\n",
            "Epoch 32/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4560 - sparse_categorical_crossentropy: 0.4560\n",
            "Epoch 33/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4581 - sparse_categorical_crossentropy: 0.4581\n",
            "Epoch 34/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4549 - sparse_categorical_crossentropy: 0.4549\n",
            "Epoch 35/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4576 - sparse_categorical_crossentropy: 0.4576\n",
            "Epoch 36/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4472 - sparse_categorical_crossentropy: 0.4472\n",
            "Epoch 37/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4554 - sparse_categorical_crossentropy: 0.4554\n",
            "Epoch 38/50\n",
            "5/5 [==============================] - 0s 38ms/step - loss: 0.4354 - sparse_categorical_crossentropy: 0.4354\n",
            "Epoch 39/50\n",
            "5/5 [==============================] - 0s 40ms/step - loss: 0.4709 - sparse_categorical_crossentropy: 0.4709\n",
            "Epoch 40/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4577 - sparse_categorical_crossentropy: 0.4577\n",
            "Epoch 41/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4573 - sparse_categorical_crossentropy: 0.4573\n",
            "Epoch 42/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4550 - sparse_categorical_crossentropy: 0.4550\n",
            "Epoch 43/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4577 - sparse_categorical_crossentropy: 0.4577\n",
            "Epoch 44/50\n",
            "5/5 [==============================] - 0s 35ms/step - loss: 0.4545 - sparse_categorical_crossentropy: 0.4545\n",
            "Epoch 45/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4559 - sparse_categorical_crossentropy: 0.4559\n",
            "Epoch 46/50\n",
            "5/5 [==============================] - 0s 39ms/step - loss: 0.4542 - sparse_categorical_crossentropy: 0.4542\n",
            "Epoch 47/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4515 - sparse_categorical_crossentropy: 0.4515\n",
            "Epoch 48/50\n",
            "5/5 [==============================] - 0s 41ms/step - loss: 0.4349 - sparse_categorical_crossentropy: 0.4349\n",
            "Epoch 49/50\n",
            "5/5 [==============================] - 0s 36ms/step - loss: 0.4359 - sparse_categorical_crossentropy: 0.4359\n",
            "Epoch 50/50\n",
            "5/5 [==============================] - 0s 37ms/step - loss: 0.4384 - sparse_categorical_crossentropy: 0.4384\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd907d59f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjUSPEarunx-",
        "colab_type": "text"
      },
      "source": [
        "### Evaluation of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMRn6Gejuj3z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7bf59530-54fb-41f7-bd6b-fa1010f026ec"
      },
      "source": [
        "model.evaluate(test_x.values, test_y.values,\n",
        "    batch_size=8)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 292ms/step\n",
            "4/4 [==============================] - 1s 292ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5004097297787666, 0.5337704]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYAWYJnJuuDj",
        "colab_type": "text"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49NpnR1Zuo7s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('./DNN_TPU_1024.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5jxMplhuw6u",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUJCspHauyk7",
        "colab_type": "text"
      },
      "source": [
        "### Prediction data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmwBNgK7uszk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "e3e0700f-83cb-4947-cf2b-91631e923117"
      },
      "source": [
        "COLUMNS_NAME=['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
        "data = pd.DataFrame(PREDICTION_INPUT_DATA, columns=COLUMNS_NAME)\n",
        "print(data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
            "0          6.9         3.1          5.4         2.1\n",
            "1          5.1         3.3          1.7         0.5\n",
            "2          5.9         3.0          4.2         1.5\n",
            "3          6.0         3.4          4.5         1.6\n",
            "4          5.5         2.5          4.0         1.3\n",
            "5          6.2         2.9          4.3         1.3\n",
            "6          5.5         4.2          1.4         0.2\n",
            "7          6.3         2.8          5.1         1.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpjkNEuWu3fJ",
        "colab_type": "text"
      },
      "source": [
        "### Prediction on TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHvIjoyvu14E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "7429a707-bfea-4c8f-a835-ac0d46a2d03a"
      },
      "source": [
        "predictions = model.predict(data.values.astype(np.float32))\n",
        "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "for pred_dict, expec in zip(predictions, PREDICTION_OUTPUT_DATA):\n",
        "  class_index = np.argmax(pred_dict)\n",
        "  class_probability = np.max(pred_dict)\n",
        "  print(template.format(SPECIES[class_index], 100*class_probability, expec))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Virginica\"\n",
            "\n",
            "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Virginica\" (55.9%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (54.6%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (56.7%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Setosa\" (100.0%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u44dwO7ru6ds",
        "colab_type": "text"
      },
      "source": [
        "### Prediction on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kQyO5mzu4fS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "bcd0aa6d-0906-4496-9cf9-dd03b97255cf"
      },
      "source": [
        "cpu_model = get_model()\n",
        "cpu_model.load_weights('./DNN_TPU_1024.h5')\n",
        "cpu_predictions = cpu_model.predict(data)\n",
        "template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "for pred_dict, expec in zip(cpu_predictions, PREDICTION_OUTPUT_DATA):\n",
        "  class_index = np.argmax(pred_dict)\n",
        "  class_probability = np.max(pred_dict)\n",
        "  print(template.format(SPECIES[class_index], 100*class_probability, expec))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Virginica\"\n",
            "\n",
            "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Virginica\" (55.9%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (54.6%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Virginica\" (56.7%), expected \"Versicolor\"\n",
            "\n",
            "Prediction is \"Setosa\" (100.0%), expected \"Setosa\"\n",
            "\n",
            "Prediction is \"Virginica\" (58.6%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIQ1Xiyou7h_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}